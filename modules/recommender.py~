'''Use of the recommendation system'''

from get_data import get_data_spotify
from preprocessing import preprocessing, preprocessed_data
from trainer import vectorization, kmeans, cluster_function, model
import pandas as pd
import gensim
from gensim.models import phrases, word2vec

def recommendation_system(user_input):
    # category = 'data science'
    # lang_input = 'en'

    # column_to_preprocess = 'title_and_description'

    # number_of_clusters = 50

    # # get the data from spotify
    # data = get_data_spotify(user_input=category, lang_input=lang_input)

    # # preprocess the data
    # data_preprocessed = preprocessed_data(data, column=column_to_preprocess)

    # change type of preprocessed column to use for tf-idf, keep other column to use for word2vec
    data_preprocessed = pd.read_csv('data/data_preprocessed.csv')
    data_preprocessed['complete_processed_str'] = data_preprocessed['complete_processed'].astype('str') # generalize how the column is called
    data_vectorized = vectorization(data_preprocessed, 'complete_processed_str')

    # create labels
    labels = kmeans(data_vectorized, number_of_clusters)

    # assign clusters to relevant episode
    df_complete = cluster_function(labels, data_preprocessed)

    # merge clusters and data_vectorized for filtering in the next step
    vec_cluster = data_vectorized.merge(df_complete['cluster'], left_index=True, right_index=True)

    # create a dictionary that assigns topic to cluster
    matching = {}

    for i in range(0, number_of_clusters):
        cluster = vec_cluster[vec_cluster['cluster'] == i]
        c = model(cluster.drop(columns='cluster'))
        matching[i] = c[0]

    # match topics to respective cluster
    df_complete['topics'] = df_complete['cluster'].map(matching)

    # list all the topics
    topics = list(matching.values())

    new_topics_list =[]

    for topic in topics:
        temp_list = []
        new_topics_list.append(temp_list)
        for word in topic:
            temp_list.append(word.replace(" ", "_"))

    new_topics_list = pd.Series(new_topics_list)
    #Corp_pre = data_preprocessed.complete_processed.append(new_topics_list)

    # create corpus for word2vec
    #corpus = Corp_pre.values

    # automatically find word connections (bigrams in corpus)
    #bigrams = phrases.Phrases(corpus)

    model_w2v = Word2Vec.load("model_word2vec.model")
    #model_w2v = word2vec.Word2Vec(bigrams[corpus], size=100, min_count=1, iter=20)

    dict_topics = {}
    for i in range (len(new_topics_list)):
        dict_topics[i] = new_topics_list[i]

    recommended_clusters = recommended_topic(user_input, list_of_topics=new_topics_list, dict_topics=dict_topics, model=model_w2v)[1]

    recommendations = recommended_episodes(recommended_clusters, df=df_complete)

    return recommendations

# function to return key for any value
def get_key(val, dict_topics):
    for key, value in dict_topics.items():
         if val == value:
                return key

    return "key doesn't exist"

def recommended_topic(user_input, list_of_topics, dict_topics, model):
    distances = {}
    for word in list_of_topics:
        distances[get_key(word, dict_topics)] = model.wv.n_similarity(word, [user_input])
    top_3 = sorted(distances, key=distances.get, reverse=True)[:3]
    max_key = max(distances, key=distances.get)
    return max_key, top_3

def recommended_episodes(recommended_clusters, df):
    episodes = {}
    for cl in recommended_clusters:
        episodes[cl] = df[df['cluster'] == cl]['episode_name'][:2]
    return pd.DataFrame(episodes)

def word2vec_model():


